{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages: \n",
    "Numpy, Numba and Pytorch\n",
    "\n",
    "### Running this Notebook\n",
    "Set the hyperparameters in cell [2]\n",
    "\n",
    "### Running the experiments through command line\n",
    "\n",
    "- for uncorrelated setting:\n",
    "```\n",
    "python train.py -n <num_agents> -l <lambda> -p <p_trunc>\n",
    "```\n",
    "\n",
    "- for correlated setting\n",
    "```\n",
    "python train_corr.py -n <num_agents> -l <lambda> -p <p_trunc> -c <p_corr>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import Data\n",
    "from net import Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the hyperparamters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "class HParams:\n",
    "    def __init__(self):\n",
    "        # Number of Agents\n",
    "        self.num_agents = 4\n",
    "        \n",
    "        # Number of Hidden Layers and Hidden Nodes\n",
    "        self.num_hidden_layers = 4\n",
    "        self.num_hidden_nodes = 256\n",
    "        \n",
    "        # Learning Rate, Batch Size, Max iterations\n",
    "        self.lr = 2e-3\n",
    "        self.batch_size = 1024\n",
    "        self.epochs = 50000\n",
    "        \n",
    "        # Printing Stats\n",
    "        self.print_iter = 100\n",
    "        self.val_iter = 1000\n",
    "        \n",
    "        # Save model @ iter\n",
    "        self.save_iter = self.epochs - 1\n",
    "        \n",
    "        # Validation Batch Size\n",
    "        self.num_val_batches = 200\n",
    "        \n",
    "        # Truncation probability\n",
    "        self.prob = 0.2\n",
    "        # Correlaiton probability\n",
    "        self.corr = 0.25\n",
    "        \n",
    "        # Trade-off param\n",
    "        self.lambd = 0.5\n",
    "                \n",
    "        # Seed\n",
    "        self.seed = 0\n",
    "        \n",
    "        \n",
    "# Initialize config\n",
    "cfg = HParams()\n",
    "device = \"cuda:0\"\n",
    "np.random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved at experiments/agents_4/corr_0.25\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.join(\"experiments\", \"agents_%d\"%(cfg.num_agents), \"corr_%.2f\"%(cfg.corr))\n",
    "model_path = os.path.join(root_dir, \"MODEL_%d_lambd_%f_prob_%.2f_corr_%.2f\"%(cfg.seed, cfg.lambd, cfg.prob, cfg.corr))\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "print(\"Model will be saved at %s\"%(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (input_block): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer_out_r): Linear(in_features=256, out_features=20, bias=True)\n",
       "  (layer_out_c): Linear(in_features=256, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "G = Data(cfg)\n",
    "\n",
    "# Neural Network\n",
    "model = Net(cfg)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_var(x): return torch.Tensor(x).to(device)\n",
    "\n",
    "# Loss functions\n",
    "def compute_st(r, p, q):        \n",
    "    wp = F.relu(p[:, :, None, :] - p[:, :, :, None])\n",
    "    wq = F.relu(q[:, :, None, :] - q[:, None, :, :], 0)  \n",
    "    t = (1 - torch.sum(r, dim = 1, keepdim = True))\n",
    "    s = (1 - torch.sum(r, dim = 2, keepdim = True))\n",
    "    rgt_1 = torch.einsum('bjc,bijc->bic', r, wq) + t * F.relu(q)\n",
    "    rgt_2 = torch.einsum('bia,biac->bic', r, wp) + s * F.relu(p)\n",
    "    regret =  rgt_1 * rgt_2 \n",
    "    return regret.sum(-1).sum(-1).mean()/cfg.num_agents\n",
    "\n",
    "def compute_ir(r, p, q):\n",
    "    ir_1 = r * F.relu(-q)\n",
    "    ir_2 = r * F.relu(-p)\n",
    "    ir = ir_1 + ir_2\n",
    "    return ir.sum(-1).sum(-1).mean()/cfg.num_agents\n",
    "\n",
    "def compute_ic_FOSD(r, p, q, P, Q, r_mult = 1):\n",
    "            \n",
    "    IC_viol_P = torch.zeros(cfg.num_agents).to(device)\n",
    "    IC_viol_Q = torch.zeros(cfg.num_agents).to(device)\n",
    "    \n",
    "    discount = torch_var((r_mult) ** np.arange(cfg.num_agents))\n",
    "\n",
    "    for agent_idx in range(cfg.num_agents):\n",
    "\n",
    "        P_mis, Q_mis = G.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = True, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, cfg.num_agents, cfg.num_agents), q_mis.view(-1, cfg.num_agents, cfg.num_agents))\n",
    "        r_mis = r_mis.view(*P_mis.shape)\n",
    "\n",
    "        r_diff = (r_mis[:, :, agent_idx, :] - r[:, None, agent_idx, :])*(p[:, None, agent_idx, :] > 0).float()\n",
    "        _, idx = torch.sort(-p[:, agent_idx, :])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "        \n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_P[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "        P_mis, Q_mis = G.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = False, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, cfg.num_agents, cfg.num_agents), q_mis.view(-1, cfg.num_agents, cfg.num_agents))\n",
    "        r_mis = r_mis.view(*Q_mis.shape)\n",
    "        \n",
    "        r_diff = (r_mis[:, :, :, agent_idx] - r[:, None, :, agent_idx])*(q[:, None, :, agent_idx] > 0).float()\n",
    "        _, idx = torch.sort(-q[:, :, agent_idx])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "        \n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_Q[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "    IC_viol = (IC_viol_P.mean() + IC_viol_Q.mean())*0.5\n",
    "    return IC_viol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = torch.optim.AdamW(model.parameters(), lr = cfg.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[10000,25000], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN-ITER]: 0, [Time-Elapsed]: 0.534615, [Total-Loss]: 0.115795\n",
      "[Stability-Viol]: 0.231356, [IC-Viol]: 0.000233\n",
      "[TRAIN-ITER]: 100, [Time-Elapsed]: 28.971549, [Total-Loss]: 0.052593\n",
      "[Stability-Viol]: 0.105065, [IC-Viol]: 0.000121\n",
      "[TRAIN-ITER]: 200, [Time-Elapsed]: 57.402748, [Total-Loss]: 0.052567\n",
      "[Stability-Viol]: 0.105017, [IC-Viol]: 0.000116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-855333622c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mst_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_st\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ic_FOSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mic_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-088b1143830e>\u001b[0m in \u001b[0;36mcompute_ic_FOSD\u001b[0;34m(r, p, q, P, Q, r_mult)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mP_mis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_misreports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_truncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mp_mis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_mis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_mis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mr_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_mis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mr_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_mis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP_mis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-088b1143830e>\u001b[0m in \u001b[0;36mtorch_var\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loss functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_st\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "tic = time.time()\n",
    "i = 0\n",
    "while i < cfg.epochs:\n",
    "  \n",
    "    # Reset opt\n",
    "    opt.zero_grad()\n",
    "    model.train()\n",
    "    \n",
    "    # Inference\n",
    "    if cfg.corr > 0:\n",
    "        P, Q = G.generate_batch_with_corr(cfg.batch_size)\n",
    "    else:\n",
    "        P, Q = G.generate_batch(cfg.batch_size)\n",
    "        \n",
    "    p, q = torch_var(P), torch_var(Q)\n",
    "    r = model(p, q)\n",
    "    \n",
    "    # Compute loss\n",
    "    st_loss = compute_st(r, p, q)\n",
    "    \n",
    "    ic_loss = compute_ic_FOSD(r, p, q, P, Q)\n",
    "        \n",
    "    total_loss = st_loss * (cfg.lambd) + ic_loss * (1 - cfg.lambd)\n",
    "    total_loss.backward() \n",
    "    \n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    t_elapsed = time.time() - tic\n",
    "\n",
    "    \n",
    "    # Validation  \n",
    "    if i% cfg.print_iter == 0 or i == cfg.epochs - 1:\n",
    "        print(\"[TRAIN-ITER]: %d, [Time-Elapsed]: %f, [Total-Loss]: %f\"%(i, t_elapsed, total_loss.item()))\n",
    "        print(\"[Stability-Viol]: %f, [IC-Viol]: %f\"%(st_loss.item(), ic_loss.item()))\n",
    "        \n",
    "    if (i>0) and (i % cfg.save_iter == 0) or i == cfg.epochs - 1:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    if ((i>0) and (i% cfg.val_iter == 0)) or i == cfg.epochs - 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_st_loss = 0.0\n",
    "            val_ic_loss = 0.0\n",
    "            for j in range(cfg.num_val_batches):\n",
    "                P, Q = G.generate_batch_with_corr(cfg.batch_size)\n",
    "                p, q = torch_var(P), torch_var(Q)\n",
    "                r = model(p, q)\n",
    "                st_loss = compute_st(r, p, q)\n",
    "                ic_loss = compute_ic_FOSD(r, p, q, P, Q)\n",
    "                val_st_loss += st_loss.item()\n",
    "                val_ic_loss += ic_loss.item()\n",
    "            print(\"\\t[VAL-ITER]: %d, [ST-Loss]: %f, [IC-Loss]: %f\"%(i, val_st_loss/cfg.num_val_batches, val_ic_loss/cfg.num_val_batches))\n",
    "            \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch_holyseas]",
   "language": "python",
   "name": "conda-env-.conda-pytorch_holyseas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
